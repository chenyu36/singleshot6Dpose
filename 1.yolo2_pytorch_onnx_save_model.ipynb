{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch-yolo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/longcw/yolo2-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgfile =  './cfg/yolo-pose.cfg' \n",
    "weightfile =  './backup/cargo/c920_cam/81_percent_frc_text/model.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from ./backup/cargo/c920_cam/81_percent_frc_text/model.weights... Done!\n"
     ]
    }
   ],
   "source": [
    "m = Darknet(cfgfile)\n",
    "m.load_weights(weightfile)\n",
    "print('Loading weights from %s... Done!' % (weightfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use Onnx to convert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/onnx/tutorials/blob/master/tutorials/PytorchOnnxExport.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrischen/Documents/singleshot6Dpose/darknet.py:27: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert(H % stride == 0)\n",
      "/home/chrischen/Documents/singleshot6Dpose/darknet.py:28: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert(W % stride == 0)\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Standard ImageNet input - 3 channels, 224x224,\n",
    "# values don't matter as we care about network structure.\n",
    "# But they can also be real inputs.\n",
    "dummy_input = Variable(torch.randn(1, 3, 416, 416))\n",
    "# Obtain your model, it can be also constructed in your script explicitly\n",
    "model = m\n",
    "# Invoke export\n",
    "torch.onnx.export(model, dummy_input, \"cargo_yolo2_c920_cam_81percent.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import tensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build engine and serialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "import tensorrt as trt\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "import common\n",
    "\n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "    \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "    def build_engine():\n",
    "        \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "        with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "            builder.max_workspace_size = 1 << 30 # 1GB\n",
    "            builder.max_batch_size = 1\n",
    "            # Parse model file\n",
    "            if not os.path.exists(onnx_file_path):\n",
    "                print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "                exit(0)\n",
    "            print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "            with open(onnx_file_path, 'rb') as model:\n",
    "                print('Beginning ONNX file parsing')\n",
    "                parser.parse(model.read())\n",
    "            print('Completed parsing of ONNX file')\n",
    "            print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "            engine = builder.build_cuda_engine(network)\n",
    "            print(\"Completed creating Engine\")\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(engine.serialize())\n",
    "            return engine\n",
    "\n",
    "    if os.path.exists(engine_file_path):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "        with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    else:\n",
    "        return build_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load a previously generated yolo network graph in ONNX format:\n",
    "onnx_file_path = './cargo_yolo2_c920_cam_81percent.onnx'\n",
    "engine_file_path = './cargo_yolo2_c920_cam_81percent.trt'\n",
    "input_image_path = './cargo_sample.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosess_img(img_path):\n",
    "    frame = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    yolo_img =cv2.resize(img, (416, 416), interpolation=cv2.INTER_AREA)\n",
    "    plt.imshow(img)\n",
    "    return yolo_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONNX file from path ./cargo_yolo2_c920_cam_81percent.onnx...\n",
      "Beginning ONNX file parsing\n"
     ]
    }
   ],
   "source": [
    "# Do inference with TensorRT\n",
    "trt_outputs = []\n",
    "with get_engine(onnx_file_path, engine_file_path) as engine, engine.create_execution_context() as context:\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "    print(type(engine))\n",
    "    img = preprosess_img(input_image_path)\n",
    "    # Do inference\n",
    "    print('Running inference on image {}...'.format(input_image_path))\n",
    "    # Set host input to the image. The common.do_inference function will copy the input to the GPU before executing.\n",
    "    inputs[0].host = img\n",
    "    trt_outputs = common.do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "    print(trt_outputs)\n",
    "    print(type(trt_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shapes = [(1,20,13,13)]\n",
    "#trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "trt_outputs = array(trt_outputs).reshape(1,20,13,13)\n",
    "# print('trt_outputs type', type(trt_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trt outputs shape ', trt_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
