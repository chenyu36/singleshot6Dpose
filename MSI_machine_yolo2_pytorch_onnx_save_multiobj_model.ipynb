{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch-yolo2 multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/longcw/yolo2-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgfile =  './multi_obj_pose_estimation/cfg/yolo-pose-multi.cfg' \n",
    "weightfile =  './multi_obj_pose_estimation/backup_multi/model.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from ./multi_obj_pose_estimation/backup_multi/model.weights... Done!\n"
     ]
    }
   ],
   "source": [
    "m = Darknet(cfgfile)\n",
    "m.load_weights(weightfile)\n",
    "print('Loading weights from %s... Done!' % (weightfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use Onnx to convert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/onnx/tutorials/blob/master/tutorials/PytorchOnnxExport.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrischen/Documents/singleshot6Dpose/darknet.py:27: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert(H % stride == 0)\n",
      "/home/chrischen/Documents/singleshot6Dpose/darknet.py:28: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert(W % stride == 0)\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Standard ImageNet input - 3 channels, 224x224,\n",
    "# values don't matter as we care about network structure.\n",
    "# But they can also be real inputs.\n",
    "dummy_input = Variable(torch.randn(1, 3, 416, 416))\n",
    "# Obtain your model, it can be also constructed in your script explicitly\n",
    "model = m\n",
    "# Invoke export\n",
    "torch.onnx.export(model, dummy_input, './trt_models/multi_objs/FRC2020models_v10_powercell_powerport.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify onnx model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the onnx model is created, it is necessary to simplify the model to avoid crash in the next step\n",
    "# ref: https://github.com/daquexian/onnx-simplifier\n",
    "# download and install the software if the system does not have the onnx-simplifier yet\n",
    "# command prompt: pip3 install onnx-simplifier\n",
    "\n",
    "# to simplify onnx model, use this format\n",
    "# python3 -m onnxsim input_onnx_model output_onnx_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import tensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build engine and serialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "import tensorrt as trt\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "import common\n",
    "\n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "#     \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "#     def build_engine():\n",
    "#         EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "#         \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "#         with trt.Builder(TRT_LOGGER) as builder, builder_config.set_flag(trt.BuilderFlag.FP16), builder.create_network(EXPLICIT_BATCH) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "#             # set builder precision\n",
    "#             builder.fp16_mode = True\n",
    "#             builder.strict_type_constraints = True\n",
    "            \n",
    "#             builder.max_workspace_size = 1 << 29 # 512MiB\n",
    "#             builder.max_batch_size = 1\n",
    "            \n",
    "\n",
    "#             #builder.int8_mode = True\n",
    "#             # Parse model file\n",
    "#             if not os.path.exists(onnx_file_path):\n",
    "#                 print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "#                 exit(0)\n",
    "#             print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "#             with open(onnx_file_path, 'rb') as model:\n",
    "#                 print('Beginning ONNX file parsing')\n",
    "#                 #parser.parse(model.read())\n",
    "#                 #parser.parse returns a bool, and we were not checking it originally.\n",
    "#                 if not parser.parse(model.read()):\n",
    "#                     print(parser.get_error(0))\n",
    "#                 print(network.get_layer(network.num_layers - 1).get_output(0).shape)\n",
    "#                 network.mark_output(network.get_layer(network.num_layers - 1).get_output(0))  \n",
    "\n",
    "#                 print('Completed parsing of ONNX file')\n",
    "#                 print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "#                 engine = builder.build_cuda_engine(network)\n",
    "#                 print(\"Completed creating Engine\")\n",
    "#                 print(engine)\n",
    "#                 with open(engine_file_path, \"wb\") as f:\n",
    "#                     f.write(engine.serialize())\n",
    "#                 return engine\n",
    "\n",
    "#     if os.path.exists(engine_file_path):\n",
    "#         # If a serialized engine exists, use it instead of building an engine.\n",
    "#         print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "#         with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "#             return runtime.deserialize_cuda_engine(f.read())\n",
    "#     else:\n",
    "#         return build_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "    \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "    def build_engine():\n",
    "        #EXPLICIT_BATCH = 1 << (int)(trt.BuilderFlag.FP16) | 1 << (int)(trt.BuilderFlag.STRICT_TYPES)\n",
    "        EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "        \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "        with trt.Builder(TRT_LOGGER) as builder, builder.create_network(EXPLICIT_BATCH) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        #with trt.Builder(TRT_LOGGER) as builder, builder.create_network(network_flags) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "            if (builder.platform_has_fast_fp16):\n",
    "                print('support fp16')\n",
    "            if (builder.platform_has_fast_int8):\n",
    "                print('support int8')\n",
    "            if (builder.fp16_mode):\n",
    "                print('fp16 kernels are permitted')\n",
    "            builder.fp16_mode = True\n",
    "            #builder.int8_mode = True\n",
    "            builder.strict_type_constraints = True\n",
    "            builder.max_workspace_size = 1 << 28 # 256MB\n",
    "            builder.max_batch_size = 1\n",
    "            # Parse model file\n",
    "            if not os.path.exists(onnx_file_path):\n",
    "                print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "                exit(0)\n",
    "            print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "            with open(onnx_file_path, 'rb') as model:\n",
    "                print('Beginning ONNX file parsing')\n",
    "                if not parser.parse(model.read()):\n",
    "                    print ('ERROR: Failed to parse the ONNX file.')\n",
    "                    for error in range(parser.num_errors):\n",
    "                        print (parser.get_error(error))\n",
    "                    return None\n",
    "            # The actual yolov3.onnx is generated with batch size 64. Reshape input to batch size 1\n",
    "            network.get_input(0).shape = [1, 3, 416, 416]\n",
    "            print('Completed parsing of ONNX file')\n",
    "            print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "            engine = builder.build_cuda_engine(network)\n",
    "            print(\"Completed creating Engine\")\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(engine.serialize())\n",
    "            return engine\n",
    "\n",
    "    if os.path.exists(engine_file_path):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "        with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    else:\n",
    "        return build_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load a previously generated yolo network graph in ONNX format:\n",
    "# However, on this machine, there is an error if using the onnx model directly\n",
    "# Run ONNX Simplifier <https://github.com/daquexian/onnx-simplifier> with the following command\n",
    "# python3 -m onnxsim input_onnx_model.onnx output_onnx_model.onnx\n",
    "#onnx_file_path = './trt_models/multi_objs/FRC2020models_v10_powercell_powerport.onnx'\n",
    "onnx_file_path = './trt_models/multi_objs/FRC2020models_v10_powercell_powerport_simplified.onnx'\n",
    "engine_file_path = './trt_models/multi_objs/FRC2020models_v10_powercell_powerport_simplified.trt'\n",
    "input_image_path = './hatchPanel_sample.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosess_img(img_path):\n",
    "    frame = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    yolo_img =cv2.resize(img, (416, 416), interpolation=cv2.INTER_AREA)\n",
    "    plt.imshow(img)\n",
    "    return yolo_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file ./trt_models/multi_objs/FRC2020models_v10_powercell_powerport_simplified.trt\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-435d2e054f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do inference with TensorRT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_execution_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f47ff6b27de7>\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(onnx_file_path, engine_file_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# If a serialized engine exists, use it instead of building an engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading engine from file {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRuntime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRT_LOGGER\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize_cuda_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "# Do inference with TensorRT\n",
    "trt_outputs = []\n",
    "with get_engine(onnx_file_path, engine_file_path) as engine, engine.create_execution_context() as context:\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "    print(type(engine))\n",
    "    img = preprosess_img(input_image_path)\n",
    "    # Do inference\n",
    "    print('Running inference on image {}...'.format(input_image_path))\n",
    "    # Set host input to the image. The common.do_inference function will copy the input to the GPU before executing.\n",
    "    inputs[0].host = img\n",
    "    trt_outputs = common.do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "    print(trt_outputs)\n",
    "    print(type(trt_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shapes = [(1,20,13,13)]\n",
    "#trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "num_classes = 4\n",
    "num_anchors = 5\n",
    "num_label_points = 19\n",
    "\n",
    "trt_outputs = array(trt_outputs).reshape(1, num_anchors*(num_label_points + num_classes),13,13)\n",
    "# print('trt_outputs type', type(trt_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trt outputs shape ', trt_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
